{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a61623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter, defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d88264d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\schel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\schel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Define functions to allow for different levels of cleaning\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_raw(text):\n",
    "    return str(text).lower().split()\n",
    "\n",
    "def clean_light(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower())  # remove punctuation and symbols\n",
    "    # text = re.sub(r'[^a-z\\s]', '', str(text).lower())  # commented out to allow for numbers\n",
    "    tokens = text.split()\n",
    "    return [w for w in tokens if w not in stop_words]\n",
    "\n",
    "def clean_moderate(text):\n",
    "    tokens = clean_light(text)\n",
    "    return [lemmatizer.lemmatize(w) for w in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07b35740",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load = pd.read_parquet(\"../data/processed/df.parquet\")\n",
    "df = df_load.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8743334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create keyword extraction function\n",
    "def extract_keywords(df, fields, cleaner_fn):\n",
    "    keyword_counter = Counter()\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        query_tokens = set(cleaner_fn(row['query']))\n",
    "        \n",
    "        for field in fields:\n",
    "            field_tokens = set(cleaner_fn(row[field]))\n",
    "            shared = query_tokens.intersection(field_tokens)\n",
    "            keyword_counter.update(shared)\n",
    "    \n",
    "    return keyword_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be5b281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Top 10: [('for', 114), ('therapy', 51), ('cold', 50), ('charger', 42), ('coffee', 41), ('tobacco', 39), ('pillow', 36), ('throw', 35), ('smoking', 34), ('black', 33)]\n",
      "Light Cleaned Top 10: [('therapy', 53), ('cold', 50), ('black', 44), ('coffee', 42), ('charger', 42), ('tobacco', 40), ('pillow', 36), ('throw', 35), ('smoking', 34), ('calcium', 34)]\n",
      "Moderate Cleaned Top 10: [('pillow', 86), ('dress', 71), ('charger', 67), ('therapy', 53), ('cold', 50), ('black', 44), ('coffee', 42), ('tobacco', 40), ('bottle', 35), ('throw', 35)]\n"
     ]
    }
   ],
   "source": [
    "# Product text fields to clean\n",
    "text_columns = ['product_title', 'product_description', 'product_bullet_point', 'product_brand', 'product_color']\n",
    "\n",
    "# Clean and extract keywords\n",
    "raw_keywords = extract_keywords(df, text_columns, clean_raw)\n",
    "light_keywords = extract_keywords(df, text_columns, clean_light)\n",
    "moderate_keywords = extract_keywords(df, text_columns, clean_moderate)\n",
    "\n",
    "print(\"Raw Top 10:\", raw_keywords.most_common(10))\n",
    "print(\"Light Cleaned Top 10:\", light_keywords.most_common(10))\n",
    "print(\"Moderate Cleaned Top 10:\", moderate_keywords.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51db5ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save extracted keywords to json dict\n",
    "raw_keywords_dict = dict(raw_keywords)\n",
    "light_keywords_dict = dict(light_keywords)\n",
    "moderate_keywords_dict = dict(moderate_keywords)\n",
    "\n",
    "with open(\"../src/text_processing/artifacts/raw_keywords.json\", \"w\") as f:\n",
    "    json.dump(raw_keywords_dict, f, indent=2)\n",
    "\n",
    "with open(\"../src/text_processing/artifacts/light_keywords.json\", \"w\") as f:\n",
    "    json.dump(light_keywords_dict, f, indent=2)\n",
    "\n",
    "with open(\"../src/text_processing/artifacts/moderate_keywords.json\", \"w\") as f:\n",
    "    json.dump(moderate_keywords_dict, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afe131f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### Try simple combining step for baseline (without imputation first)\n",
    "\n",
    "#### Future Optimization Notes\n",
    "\n",
    "* Text Component Ordering: Consider reordering fields in `combine_product_text()` to prioritize short, essential fields first:\n",
    "  - Current: Title > Description > Features > Brand > Color  \n",
    "  - Better: Title > Brand > Color > Features > Description\n",
    "  - Prevents truncation of critical search attributes (brand/color) when hitting character limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08273dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text combination and processing functions (future src/text_processing/)\n",
    "def simple_clean_text(text):\n",
    "    \"\"\"Minimal text cleaning for baseline.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    return str(text).lower().strip()\n",
    "\n",
    "# max_chars at 2000 to begin but may need to adjust truncations to be below ~512 for transformer models\n",
    "def combine_product_text(row, max_chars=2000, use_imputation=False):\n",
    "    \"\"\"Combine product text fields into single string for embedding.\"\"\"\n",
    "    # Get text fields\n",
    "    title = simple_clean_text(row['product_title'])\n",
    "    description = simple_clean_text(row['product_description'])\n",
    "    bullet_point = simple_clean_text(row['product_bullet_point'])\n",
    "    brand = simple_clean_text(row['product_brand'])\n",
    "    color = simple_clean_text(row['product_color'])\n",
    "    \n",
    "    # Optional imputation (for later comparison)\n",
    "    if use_imputation:\n",
    "        # Use bullet_point for missing description\n",
    "        if not description and bullet_point:\n",
    "            description = bullet_point\n",
    "        # Use description for missing bullet_point (truncated)\n",
    "        if not bullet_point and description:\n",
    "            bullet_point = description[:500]\n",
    "    \n",
    "    # Combine with clear separators\n",
    "    components = []\n",
    "    if title:\n",
    "        components.append(f\"Title: {title}\")\n",
    "    if description:\n",
    "        components.append(f\"Description: {description}\")\n",
    "    if bullet_point:\n",
    "        components.append(f\"Bullets: {bullet_point}\")\n",
    "    if brand:\n",
    "        components.append(f\"Brand: {brand}\")\n",
    "    if color:\n",
    "        components.append(f\"Color: {color}\")\n",
    "    \n",
    "    combined = \" | \".join(components)\n",
    "    \n",
    "    # Truncate if too long\n",
    "    if len(combined) > max_chars:\n",
    "        combined = combined[:max_chars].rsplit(' ', 1)[0] + \"...\"\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc3bb667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>query</th>\n",
       "      <th>query_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>split</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_description</th>\n",
       "      <th>product_bullet_point</th>\n",
       "      <th>product_brand</th>\n",
       "      <th>product_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20232</td>\n",
       "      <td>1 cup coffee maker without water reservoir</td>\n",
       "      <td>711</td>\n",
       "      <td>B07GV2S1GS</td>\n",
       "      <td>train</td>\n",
       "      <td>Keurig K-Mini Coffee Maker, Single Serve K-Cup...</td>\n",
       "      <td>None</td>\n",
       "      <td>FITS ANYWHERE: Less than 5 inches wide, perfec...</td>\n",
       "      <td>Keurig</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   example_id                                       query  query_id  \\\n",
       "0       20232  1 cup coffee maker without water reservoir       711   \n",
       "\n",
       "   product_id  split                                      product_title  \\\n",
       "0  B07GV2S1GS  train  Keurig K-Mini Coffee Maker, Single Serve K-Cup...   \n",
       "\n",
       "  product_description                               product_bullet_point  \\\n",
       "0                None  FITS ANYWHERE: Less than 5 inches wide, perfec...   \n",
       "\n",
       "  product_brand product_color  \n",
       "0        Keurig         Black  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17934e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combine_product_text function:\n",
      "Query: 1 cup coffee maker without water reservoir\n",
      "Combined text (baseline): Title: keurig k-mini coffee maker, single serve k-cup pod coffee brewer, 6 to 12 oz. brew sizes, matte black | Bullets: fits anywhere: less than 5 inches wide, perfect for small spaces\n",
      "your perfect am...\n",
      "Combined text (with imputation): Title: keurig k-mini coffee maker, single serve k-cup pod coffee brewer, 6 to 12 oz. brew sizes, matte black | Description: fits anywhere: less than 5 inches wide, perfect for small spaces\n",
      "your perfec...\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "print(\"Testing combine_product_text function:\")\n",
    "sample_row = df.iloc[0]\n",
    "print(f\"Query: {sample_row['query']}\")\n",
    "print(f\"Combined text (baseline): {combine_product_text(sample_row)[:200]}...\")\n",
    "print(f\"Combined text (with imputation): {combine_product_text(sample_row, use_imputation=True)[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ee58b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset comparison:\n",
      "Baseline combined text - Min: 15, Max: 2002, Mean: 1109.2\n",
      "Imputed combined text - Min: 15, Max: 2002, Mean: 1276.7\n",
      "\n",
      "Rows with empty combined text - Baseline: 0, Imputed: 0\n"
     ]
    }
   ],
   "source": [
    "# Create baseline and comparison datasets\n",
    "## Baseline: minimal cleaning, no imputation\n",
    "df_baseline = df.copy()\n",
    "df_baseline['combined_text'] = df_baseline.apply(\n",
    "    lambda row: combine_product_text(row, max_chars=2000, use_imputation=False), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "## Comparison: with imputation (for later analysis)\n",
    "df_imputed = df.copy()\n",
    "df_imputed['combined_text'] = df_imputed.apply(\n",
    "    lambda row: combine_product_text(row, max_chars=2000, use_imputation=True), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"Dataset comparison:\")\n",
    "print(f\"Baseline combined text - Min: {df_baseline['combined_text'].str.len().min()}, \"\n",
    "      f\"Max: {df_baseline['combined_text'].str.len().max()}, \"\n",
    "      f\"Mean: {df_baseline['combined_text'].str.len().mean():.1f}\")\n",
    "\n",
    "print(f\"Imputed combined text - Min: {df_imputed['combined_text'].str.len().min()}, \"\n",
    "      f\"Max: {df_imputed['combined_text'].str.len().max()}, \"\n",
    "      f\"Mean: {df_imputed['combined_text'].str.len().mean():.1f}\")\n",
    "\n",
    "# Check how many rows have empty combined text\n",
    "empty_baseline = (df_baseline['combined_text'].str.len() == 0).sum()\n",
    "empty_imputed = (df_imputed['combined_text'].str.len() == 0).sum()\n",
    "print(f\"\\nRows with empty combined text - Baseline: {empty_baseline}, Imputed: {empty_imputed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "837fdbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preliminarily processed datasets\n",
    "df_baseline.to_parquet(\"../data/processed/df_baseline_clean.parquet\")\n",
    "df_imputed.to_parquet(\"../data/processed/df_imputed_clean.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0af815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f946ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
