{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lancedb\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "from scipy.sparse import load_npz\n",
        "import pyarrow as pa\n",
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "from src.evaluation.metrics import calculate_hits_at_k, calculate_mrr, evaluate_search_system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Df shape: (519, 11)\n",
            "Unique queries: 53\n",
            "Columns: ['example_id', 'query', 'query_id', 'product_id', 'split', 'product_title', 'product_description', 'product_bullet_point', 'product_brand', 'product_color', 'combined_text']\n"
          ]
        }
      ],
      "source": [
        "# Load baseline dataset\n",
        "df_baseline = pd.read_parquet(\"../data/processed/df_baseline_clean.parquet\")\n",
        "df = df_baseline.copy()\n",
        "print(f\"Df shape: {df.shape}\")\n",
        "print(f\"Unique queries: {len(df['query'].unique())}\")\n",
        "print(f\"Columns: {list(df.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Transformer embeddings shape: (519, 384)\n",
            "Model used: all-MiniLM-L6-v2\n",
            "TF-IDF matrix shape: (519, 1000)\n"
          ]
        }
      ],
      "source": [
        "# Load transformer embeddings\n",
        "transformer_embeddings = np.load(\"../src/embeddings/baseline/transformer_embeddings.npy\")\n",
        "print(f\"\\nTransformer embeddings shape: {transformer_embeddings.shape}\")\n",
        "\n",
        "# Load model name\n",
        "with open(\"../src/embeddings/baseline/transformer_model_name.txt\", \"r\") as f:\n",
        "    model_name = f.read().strip()\n",
        "print(f\"Model used: {model_name}\")\n",
        "\n",
        "# Load TF-IDF artifacts for baseline comparison\n",
        "tfidf_matrix = load_npz(\"../src/vector_stores/baseline/tfidf_matrix.npz\")\n",
        "with open(\"../src/vector_stores/baseline/tfidf_vectorizer.pkl\", \"rb\") as f:\n",
        "    tfidf_vectorizer = pickle.load(f)\n",
        "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Re-using same evaluation metrics from notebook 03 placed into evaluation/metrics.py\n",
        "# This is a simple function to print the evaluation results\n",
        "def print_evaluation_results(results, method_name):\n",
        "    \"\"\"Pretty print evaluation results\"\"\"\n",
        "    print(f\"\\n--- {method_name} Performance ---\")\n",
        "    print(f\"HITS@1:  {results['hits_at_1']:.3f}\")\n",
        "    print(f\"HITS@5:  {results['hits_at_5']:.3f}\")\n",
        "    print(f\"HITS@10: {results['hits_at_10']:.3f}\")\n",
        "    print(f\"MRR:     {results['mrr']:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded transformer model: all-MiniLM-L6-v2\n"
          ]
        }
      ],
      "source": [
        "# Load the transformer model for query embedding\n",
        "## Use simple cosine similarity search for now\n",
        "transformer_model = SentenceTransformer(model_name)\n",
        "print(f\"Loaded transformer model: {model_name}\")\n",
        "\n",
        "def simple_cosine_search(query, df, embeddings, model, top_k=10):\n",
        "    \"\"\"Simple cosine similarity search using pre-computed embeddings\"\"\"\n",
        "    # Embed the query\n",
        "    query_embedding = model.encode([query])\n",
        "    \n",
        "    # Calculate cosine similarities\n",
        "    similarities = cosine_similarity(query_embedding, embeddings)[0]\n",
        "    \n",
        "    # Get top-k most similar products\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "    \n",
        "    # Return results with scores\n",
        "    results = df.iloc[top_indices].copy()\n",
        "    results['score'] = similarities[top_indices]\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing simple cosine search with query: 'coffee maker'\n",
            "\n",
            "Search time: 0.1697 seconds\n",
            "\n",
            "Top 5 results:\n",
            "Score: 0.602 | Presto 02835 MyJo Single Cup Coffee Maker, Black...\n",
            "Score: 0.593 | Cuisinart DCC-3200P1 Perfectemp Coffee Maker, 14 Cup Progammable with Glass Cara...\n",
            "Score: 0.587 | CHEFMAN Single Serve One Cup Coffee Maker, up to 14 Oz, InstaCoffee Brews in 30 ...\n",
            "Score: 0.576 | Hamilton Beach (47950) Coffee Maker with 12 Cup Capacity & Internal Storage Coff...\n",
            "Score: 0.563 | Elite Gourmet EHC111A Maxi-Matic Personal 14oz Single-Serve Compact Coffee Maker...\n"
          ]
        }
      ],
      "source": [
        "# Test simple cosine search\n",
        "test_query = \"coffee maker\"\n",
        "print(f\"Testing simple cosine search with query: '{test_query}'\")\n",
        "\n",
        "start_time = time.time()\n",
        "simple_results = simple_cosine_search(test_query, df_baseline, transformer_embeddings, transformer_model, top_k=5)\n",
        "simple_search_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nSearch time: {simple_search_time:.4f} seconds\")\n",
        "print(\"\\nTop 5 results:\")\n",
        "for idx, row in simple_results.iterrows():\n",
        "    print(f\"Score: {row['score']:.3f} | {row['product_title'][:80]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup LanceDB table with our embeddings and metadata\n",
        "def create_lancedb_table(df, embeddings, db_path=\"../src/vector_databases/lancedb\"):\n",
        "    \"\"\"Create LanceDB table with embeddings and metadata\"\"\"\n",
        "    # Connect to LanceDB\n",
        "    db = lancedb.connect(db_path)\n",
        "    \n",
        "    # Prepare data for LanceDB: list of dictionaries with vectors\n",
        "    data = []\n",
        "    for idx, (_, row) in enumerate(df.iterrows()):\n",
        "        data.append({\n",
        "            \"vector\": embeddings[idx].tolist(),  # Convert numpy array to list\n",
        "            \"product_id\": row['product_id'],\n",
        "            \"query\": row['query'],\n",
        "            \"product_title\": row['product_title'],\n",
        "            \"product_description\": row.get('product_description', ''),\n",
        "            \"product_bullet_point\": row.get('product_bullet_point', ''),\n",
        "            \"product_brand\": row.get('product_brand', ''),\n",
        "            \"product_color\": row.get('product_color', ''),\n",
        "            \"combined_text\": row['combined_text'],\n",
        "        })\n",
        "    \n",
        "    # Create table (drop if exists)\n",
        "    table_name = \"products\"\n",
        "    if table_name in db.table_names():\n",
        "        db.drop_table(table_name)\n",
        "    \n",
        "    table = db.create_table(table_name, data)\n",
        "    \n",
        "    print(f\"Created LanceDB table with {len(data)} vectors\")\n",
        "    print(f\"Vector dimension: {len(embeddings[0])}\")\n",
        "    print(f\"Database path: {db_path}\")\n",
        "    \n",
        "    return db, table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created LanceDB table with 519 vectors\n",
            "Vector dimension: 384\n",
            "Database path: ../src/vector_databases/lancedb\n"
          ]
        }
      ],
      "source": [
        "# Create LanceDB table\n",
        "db, lance_table = create_lancedb_table(df_baseline, transformer_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Implement search functions using LanceDB's vector search capabilities.\n",
        "def lancedb_search(query, df, table, model, top_k=10):\n",
        "    \"\"\"Search using LanceDB vector similarity\"\"\"\n",
        "    \n",
        "    # Embed the query\n",
        "    query_embedding = model.encode([query])[0]\n",
        "    # Perform vector search\n",
        "    results = table.search(query_embedding).distance_type(\"cosine\").limit(top_k).to_pandas()\n",
        "    \n",
        "    # Add score column\n",
        "    results['score'] = 1 - results['_distance']  # Convert distance to similarity\n",
        "    # Sort by score descending to match simple cosine order - NOT NEEDED\n",
        "    ## results = results.sort_values('score', ascending=False)\n",
        "    return results\n",
        "\n",
        "def lancedb_search_with_filter(query, df, table, model, filter_condition=None, top_k=10):\n",
        "    \"\"\"Search using LanceDB with metadata filtering\"\"\"\n",
        "    \n",
        "    # Embed the query\n",
        "    query_embedding = model.encode([query])[0]\n",
        "    # Perform vector search with optional filtering\n",
        "    search_query = table.search(query_embedding).distance_type(\"cosine\").limit(top_k)\n",
        "    \n",
        "    if filter_condition:\n",
        "        search_query = search_query.where(filter_condition)\n",
        "    \n",
        "    results = search_query.to_pandas()\n",
        "    # Add score column\n",
        "    results['score'] = 1 - results['_distance']\n",
        "    # Sort by score descending to match simple cosine order - NOT NEEDED\n",
        "    ## results = results.sort_values('score', ascending=False)\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing LanceDB search with query: 'coffee maker'\n",
            "\n",
            "LanceDB search time: 0.1741 seconds\n",
            "\n",
            "Top 5 LanceDB results:\n",
            "Score: 0.602 | Presto 02835 MyJo Single Cup Coffee Maker, Black...\n",
            "Score: 0.593 | Cuisinart DCC-3200P1 Perfectemp Coffee Maker, 14 Cup Progammable with Glass Cara...\n",
            "Score: 0.587 | CHEFMAN Single Serve One Cup Coffee Maker, up to 14 Oz, InstaCoffee Brews in 30 ...\n",
            "Score: 0.576 | Hamilton Beach (47950) Coffee Maker with 12 Cup Capacity & Internal Storage Coff...\n",
            "Score: 0.563 | Elite Gourmet EHC111A Maxi-Matic Personal 14oz Single-Serve Compact Coffee Maker...\n",
            "\n",
            "Performance comparison:\n",
            "Simple cosine: 0.1697s\n",
            "LanceDB:       0.1741s\n"
          ]
        }
      ],
      "source": [
        "# Test LanceDB search - without filter for now\n",
        "print(f\"Testing LanceDB search with query: '{test_query}'\")\n",
        "\n",
        "start_time = time.time()\n",
        "lance_results = lancedb_search(test_query, df_baseline, lance_table, transformer_model, top_k=5)\n",
        "lance_search_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nLanceDB search time: {lance_search_time:.4f} seconds\")\n",
        "print(\"\\nTop 5 LanceDB results:\")\n",
        "for idx, row in lance_results.iterrows():\n",
        "    print(f\"Score: {row['score']:.3f} | {row['product_title'][:80]}...\")\n",
        "\n",
        "print(f\"\\nPerformance comparison:\")\n",
        "print(f\"Simple cosine: {simple_search_time:.4f}s\")\n",
        "print(f\"LanceDB:       {lance_search_time:.4f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Same results and comparable performance time but simple cosine slightly faster:\n",
        "  * VDBs provide perf. value at scale, but maybe not for such small datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Also look at TF-IDF search for comparison\n",
        "def tfidf_search(query, df, tfidf_matrix, vectorizer, top_k=10):\n",
        "    \"\"\"TF-IDF search - baseline approach from notebook 03\"\"\"\n",
        "    # Transform query using fitted vectorizer\n",
        "    query_vector = vectorizer.transform([query])\n",
        "    # Calculate cosine similarities\n",
        "    similarities = cosine_similarity(query_vector, tfidf_matrix)[0]\n",
        "    # Get top-k most similar products\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "    # Return results with scores\n",
        "    results = df.iloc[top_indices].copy()\n",
        "    results['score'] = similarities[top_indices]\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing TF-IDF search with query: 'coffee maker'\n",
            "\n",
            "TF-IDF search time: 0.4533 seconds\n",
            "\n",
            "Top 5 TF-IDF results:\n",
            "Score: 0.750 | Outon Coffee Maker 10 Cup, Programmable Drip Coffee Maker, Multiple Brew Strengt...\n",
            "Score: 0.641 | Elite Gourmet EHC111A Maxi-Matic Personal 14oz Single-Serve Compact Coffee Maker...\n",
            "Score: 0.616 | CHULUX Single Cup Coffee Maker Machine,12 Ounce Pod Coffee Brewer,One Touch Func...\n",
            "Score: 0.589 | CHEFMAN Single Serve One Cup Coffee Maker, up to 14 Oz, InstaCoffee Brews in 30 ...\n",
            "Score: 0.550 | Single Serve K Cup Coffee Maker for K-Cup Pods and Ground Coffee, Compact Design...\n"
          ]
        }
      ],
      "source": [
        "# Test TF-IDF search for comparison\n",
        "print(f\"Testing TF-IDF search with query: '{test_query}'\")\n",
        "\n",
        "start_time = time.time()\n",
        "tfidf_results = tfidf_search(test_query, df_baseline, tfidf_matrix, tfidf_vectorizer, top_k=5)\n",
        "tfidf_search_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nTF-IDF search time: {tfidf_search_time:.4f} seconds\")\n",
        "print(\"\\nTop 5 TF-IDF results:\")\n",
        "for idx, row in tfidf_results.iterrows():\n",
        "    print(f\"Score: {row['score']:.3f} | {row['product_title'][:80]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* TF-IDF search took longer due to larger matrix.\n",
        "* Also returned different results from simple cosine and lancedb but Elite and CHEFMAN returned (different position though) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "COMPREHENSIVE SEARCH METHOD EVALUATION\n",
            "============================================================\n",
            "\n",
            "1. Evaluating TF-IDF baseline...\n",
            "Evaluating on 53 unique queries...\n",
            "\n",
            "--- TF-IDF Baseline Performance ---\n",
            "HITS@1:  0.849\n",
            "HITS@5:  0.906\n",
            "HITS@10: 0.943\n",
            "MRR:     0.869\n",
            "\n",
            "2. Evaluating simple cosine similarity...\n",
            "Evaluating on 53 unique queries...\n",
            "\n",
            "--- Simple Cosine Similarity Performance ---\n",
            "HITS@1:  0.981\n",
            "HITS@5:  0.981\n",
            "HITS@10: 0.981\n",
            "MRR:     0.981\n",
            "\n",
            "3. Evaluating LanceDB vector search...\n",
            "Evaluating on 53 unique queries...\n",
            "\n",
            "--- LanceDB Vector Search Performance ---\n",
            "HITS@1:  0.981\n",
            "HITS@5:  0.981\n",
            "HITS@10: 0.981\n",
            "MRR:     0.981\n",
            "\n",
            "============================================================\n",
            "SUMMARY COMPARISON\n",
            "============================================================\n",
            "          Method  HITS@1  HITS@5  HITS@10    MRR\n",
            "0         TF-IDF   0.849   0.906    0.943  0.869\n",
            "1  Simple Cosine   0.981   0.981    0.981  0.981\n",
            "2        LanceDB   0.981   0.981    0.981  0.981\n",
            "\n",
            "----  Key Insights  ----\n",
            "Best HITS@1: Simple Cosine (0.981)\n",
            "Best MRR: Simple Cosine (0.981)\n",
            "Simple Cosine vs LanceDB accuracy difference: 0.000\n"
          ]
        }
      ],
      "source": [
        "# Evaluate all 3 approaches together with HITS@K and MRR metrics\n",
        "print(\"=\" * 60)\n",
        "print(\"COMPREHENSIVE SEARCH METHOD EVALUATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Evaluate TF-IDF baseline\n",
        "print(\"\\n1. Evaluating TF-IDF baseline...\")\n",
        "tfidf_metrics = evaluate_search_system(\n",
        "    df_baseline, tfidf_search, tfidf_matrix, tfidf_vectorizer\n",
        ")\n",
        "print_evaluation_results(tfidf_metrics, \"TF-IDF Baseline\")\n",
        "\n",
        "# Evaluate simple cosine similarity\n",
        "print(\"\\n2. Evaluating simple cosine similarity...\")\n",
        "cosine_metrics = evaluate_search_system(\n",
        "    df_baseline, simple_cosine_search, transformer_embeddings, transformer_model\n",
        ")\n",
        "print_evaluation_results(cosine_metrics, \"Simple Cosine Similarity\")\n",
        "\n",
        "# Evaluate LanceDB\n",
        "print(\"\\n3. Evaluating LanceDB vector search...\")\n",
        "lance_metrics = evaluate_search_system(\n",
        "    df_baseline, lancedb_search, lance_table, transformer_model\n",
        ")\n",
        "print_evaluation_results(lance_metrics, \"LanceDB Vector Search\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SUMMARY COMPARISON\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create comparison table\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Method': ['TF-IDF', 'Simple Cosine', 'LanceDB'],\n",
        "    'HITS@1': [tfidf_metrics['hits_at_1'], cosine_metrics['hits_at_1'], lance_metrics['hits_at_1']],\n",
        "    'HITS@5': [tfidf_metrics['hits_at_5'], cosine_metrics['hits_at_5'], lance_metrics['hits_at_5']],\n",
        "    'HITS@10': [tfidf_metrics['hits_at_10'], cosine_metrics['hits_at_10'], lance_metrics['hits_at_10']],\n",
        "    'MRR': [tfidf_metrics['mrr'], cosine_metrics['mrr'], lance_metrics['mrr']]\n",
        "})\n",
        "\n",
        "print(comparison_df.round(3))\n",
        "\n",
        "# Performance insights\n",
        "print(\"\\n----  Key Insights  ----\")\n",
        "print(f\"Best HITS@1: {comparison_df.loc[comparison_df['HITS@1'].idxmax(), 'Method']} ({comparison_df['HITS@1'].max():.3f})\")\n",
        "print(f\"Best MRR: {comparison_df.loc[comparison_df['MRR'].idxmax(), 'Method']} ({comparison_df['MRR'].max():.3f})\")\n",
        "print(f\"Simple Cosine vs LanceDB accuracy difference: {abs(cosine_metrics['hits_at_1'] - lance_metrics['hits_at_1']):.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Wrote evaluation for definite winner but simple cosine and lancedb are equivalent - simple cosine chosen since it was 'first' for the tie.\n",
        "* At small scale (519 items), simple cosine and LanceDB appear equivalent.  Choice between them depends on prod reqs:\n",
        "  * applying metadata info, filtering, and scalability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "METADATA FILTERING EXAMPLE\n",
            "----------------------------------------\n",
            "Query: 'wireless headphones'\n",
            "\n",
            "Regular search results:\n",
            "Score: 0.378 | Brand: Nike | Nike Jacquard Hairbands 6 pack...\n",
            "Score: 0.324 | Brand: CARESHINE | Full Face Mask with Free Adjustable Headgear Gel Full Face M...\n",
            "Score: 0.306 | Brand: ZIKU | Compact Wireless Charger. ZIKU 3 in 1 Foldable 15W Wireless ...\n",
            "Score: 0.295 | Brand: Nike | Nike Dri-Fit Headband Home & Away...\n",
            "Score: 0.284 | Brand: Nike | Nike Speed Performance Headband(Black/White, Osfm)...\n",
            "\n",
            "Top brands in dataset: ['Nike', 'DC', 'Apple', \"Rubie's\", 'Crocs']\n",
            "\n",
            "Filtered search (brand = 'Nike'):\n",
            "Score: 0.378 | Brand: Nike | Nike Jacquard Hairbands 6 pack...\n",
            "Score: 0.295 | Brand: Nike | Nike Dri-Fit Headband Home & Away...\n",
            "Score: 0.284 | Brand: Nike | Nike Speed Performance Headband(Black/White, Osfm)...\n",
            "Score: 0.274 | Brand: Nike | Nike Men's Printed Dri-FIT Head Tie (Dark_Grey_Black_White)...\n",
            "Score: 0.270 | Brand: Nike | Nike Swoosh Sport Headbands 6pk (One Size Fits Most, Black/W...\n"
          ]
        }
      ],
      "source": [
        "# Show how vector db can combine semantic search with metadata filtering (product brand keyword)\n",
        "print(\"METADATA FILTERING EXAMPLE\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "query = \"wireless headphones\"\n",
        "print(f\"Query: '{query}'\")\n",
        "\n",
        "# Regular search\n",
        "regular_results = lancedb_search(query, df_baseline, lance_table, transformer_model, top_k=5)\n",
        "print(\"\\nRegular search results:\")\n",
        "for idx, row in regular_results.iterrows():\n",
        "    brand = row.get('product_brand', 'N/A')\n",
        "    print(f\"Score: {row['score']:.3f} | Brand: {brand} | {row['product_title'][:60]}...\")\n",
        "\n",
        "# Check available brands for filtering\n",
        "available_brands = df_baseline['product_brand'].value_counts().head(10)\n",
        "print(f\"\\nTop brands in dataset: {list(available_brands.index[:5])}\")\n",
        "\n",
        "# Filtered search (if we have brand data)\n",
        "if not df_baseline['product_brand'].isna().all():\n",
        "    popular_brand = available_brands.index[0] if len(available_brands) > 0 else None\n",
        "    if popular_brand and popular_brand != '':\n",
        "        print(f\"\\nFiltered search (brand = '{popular_brand}'):\")\n",
        "        filtered_results = lancedb_search_with_filter(\n",
        "            query, df_baseline, lance_table, transformer_model, \n",
        "            filter_condition=f\"product_brand = '{popular_brand}'\", top_k=5\n",
        "        )\n",
        "        for idx, row in filtered_results.iterrows():\n",
        "            print(f\"Score: {row['score']:.3f} | Brand: {row['product_brand']} | {row['product_title'][:60]}...\")\n",
        "    else:\n",
        "        print(\"\\nNote: Limited brand metadata available for filtering demo\")\n",
        "else:\n",
        "    print(\"\\nNote: No brand metadata available for filtering demo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BATCH OPERATIONS COMPARISON\n",
            "----------------------------------------\n",
            "Testing batch operations with 10 queries\n",
            "\n",
            "Simple cosine similarity (individual queries):\n",
            "Time for 10 queries: 0.1443 seconds\n",
            "Average time per query: 0.0144 seconds\n",
            "\n",
            "LanceDB (individual queries):\n",
            "Time for 10 queries: 0.1717 seconds\n",
            "Average time per query: 0.0172 seconds\n",
            "\n",
            "Batch performance comparison:\n",
            "Simple cosine: 0.1443s total (0.0144s per query)\n",
            "LanceDB:       0.1717s total (0.0172s per query)\n"
          ]
        }
      ],
      "source": [
        "# Show how vector db can perform batch operations for multiple queries\n",
        "print(\"BATCH OPERATIONS COMPARISON\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Select multiple test queries\n",
        "test_queries = df_baseline['query'].unique()[:10]  # First 10 unique queries\n",
        "print(f\"Testing batch operations with {len(test_queries)} queries\")\n",
        "\n",
        "# Simple cosine similarity batch\n",
        "print(\"\\nSimple cosine similarity (individual queries):\")\n",
        "start_time = time.time()\n",
        "cosine_batch_results = []\n",
        "for query in test_queries:\n",
        "    result = simple_cosine_search(query, df_baseline, transformer_embeddings, transformer_model, top_k=5)\n",
        "    cosine_batch_results.append(result)\n",
        "cosine_batch_time = time.time() - start_time\n",
        "print(f\"Time for {len(test_queries)} queries: {cosine_batch_time:.4f} seconds\")\n",
        "print(f\"Average time per query: {cosine_batch_time/len(test_queries):.4f} seconds\")\n",
        "\n",
        "# LanceDB batch\n",
        "print(\"\\nLanceDB (individual queries):\")\n",
        "start_time = time.time()\n",
        "lance_batch_results = []\n",
        "for query in test_queries:\n",
        "    result = lancedb_search(query, df_baseline, lance_table, transformer_model, top_k=5)\n",
        "    lance_batch_results.append(result)\n",
        "lance_batch_time = time.time() - start_time\n",
        "print(f\"Time for {len(test_queries)} queries: {lance_batch_time:.4f} seconds\")\n",
        "print(f\"Average time per query: {lance_batch_time/len(test_queries):.4f} seconds\")\n",
        "\n",
        "# Performance comparison\n",
        "print(f\"\\nBatch performance comparison:\")\n",
        "print(f\"Simple cosine: {cosine_batch_time:.4f}s total ({cosine_batch_time/len(test_queries):.4f}s per query)\")\n",
        "print(f\"LanceDB:       {lance_batch_time:.4f}s total ({lance_batch_time/len(test_queries):.4f}s per query)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BATCH OPERATIONS COMPARISON (with more queries - n=30)\n",
            "----------------------------------------\n",
            "Testing batch operations with 30 queries\n",
            "\n",
            "Simple cosine similarity (individual queries):\n",
            "Time for 30 queries: 0.3758 seconds\n",
            "Average time per query: 0.0125 seconds\n",
            "\n",
            "LanceDB (individual queries):\n",
            "Time for 30 queries: 0.4919 seconds\n",
            "Average time per query: 0.0164 seconds\n",
            "\n",
            "Batch performance comparison:\n",
            "Simple cosine: 0.3758s total (0.0125s per query)\n",
            "LanceDB:       0.4919s total (0.0164s per query)\n"
          ]
        }
      ],
      "source": [
        "# Show how vector db can perform batch operations for multiple queries\n",
        "print(\"BATCH OPERATIONS COMPARISON (with more queries - n=30)\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Select multiple test queries\n",
        "test_queries = df_baseline['query'].unique()[:30]  # Up it to first 30 unique queries\n",
        "print(f\"Testing batch operations with {len(test_queries)} queries\")\n",
        "\n",
        "# Simple cosine similarity batch\n",
        "print(\"\\nSimple cosine similarity (individual queries):\")\n",
        "start_time = time.time()\n",
        "cosine_batch_results = []\n",
        "for query in test_queries:\n",
        "    result = simple_cosine_search(query, df_baseline, transformer_embeddings, transformer_model, top_k=5)\n",
        "    cosine_batch_results.append(result)\n",
        "cosine_batch_time = time.time() - start_time\n",
        "print(f\"Time for {len(test_queries)} queries: {cosine_batch_time:.4f} seconds\")\n",
        "print(f\"Average time per query: {cosine_batch_time/len(test_queries):.4f} seconds\")\n",
        "\n",
        "# LanceDB batch\n",
        "print(\"\\nLanceDB (individual queries):\")\n",
        "start_time = time.time()\n",
        "lance_batch_results = []\n",
        "for query in test_queries:\n",
        "    result = lancedb_search(query, df_baseline, lance_table, transformer_model, top_k=5)\n",
        "    lance_batch_results.append(result)\n",
        "lance_batch_time = time.time() - start_time\n",
        "print(f\"Time for {len(test_queries)} queries: {lance_batch_time:.4f} seconds\")\n",
        "print(f\"Average time per query: {lance_batch_time/len(test_queries):.4f} seconds\")\n",
        "\n",
        "# Performance comparison\n",
        "print(f\"\\nBatch performance comparison:\")\n",
        "print(f\"Simple cosine: {cosine_batch_time:.4f}s total ({cosine_batch_time/len(test_queries):.4f}s per query)\")\n",
        "print(f\"LanceDB:       {lance_batch_time:.4f}s total ({lance_batch_time/len(test_queries):.4f}s per query)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BATCH OPERATIONS COMPARISON (with more queries - n=50)\n",
            "----------------------------------------\n",
            "Testing batch operations with 50 queries\n",
            "\n",
            "Simple cosine similarity (individual queries):\n",
            "Time for 50 queries: 0.7599 seconds\n",
            "Average time per query: 0.0152 seconds\n",
            "\n",
            "LanceDB (individual queries):\n",
            "Time for 50 queries: 0.9958 seconds\n",
            "Average time per query: 0.0199 seconds\n",
            "\n",
            "Batch performance comparison:\n",
            "Simple cosine: 0.7599s total (0.0152s per query)\n",
            "LanceDB:       0.9958s total (0.0199s per query)\n"
          ]
        }
      ],
      "source": [
        "# Show how vector db can perform batch operations for multiple queries\n",
        "print(\"BATCH OPERATIONS COMPARISON (with more queries - n=50)\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Select multiple test queries\n",
        "test_queries = df_baseline['query'].unique()[:50]  # Up it to first 50 unique queries - almost all\n",
        "print(f\"Testing batch operations with {len(test_queries)} queries\")\n",
        "\n",
        "# Simple cosine similarity batch\n",
        "print(\"\\nSimple cosine similarity (individual queries):\")\n",
        "start_time = time.time()\n",
        "cosine_batch_results = []\n",
        "for query in test_queries:\n",
        "    result = simple_cosine_search(query, df_baseline, transformer_embeddings, transformer_model, top_k=5)\n",
        "    cosine_batch_results.append(result)\n",
        "cosine_batch_time = time.time() - start_time\n",
        "print(f\"Time for {len(test_queries)} queries: {cosine_batch_time:.4f} seconds\")\n",
        "print(f\"Average time per query: {cosine_batch_time/len(test_queries):.4f} seconds\")\n",
        "\n",
        "# LanceDB batch\n",
        "print(\"\\nLanceDB (individual queries):\")\n",
        "start_time = time.time()\n",
        "lance_batch_results = []\n",
        "for query in test_queries:\n",
        "    result = lancedb_search(query, df_baseline, lance_table, transformer_model, top_k=5)\n",
        "    lance_batch_results.append(result)\n",
        "lance_batch_time = time.time() - start_time\n",
        "print(f\"Time for {len(test_queries)} queries: {lance_batch_time:.4f} seconds\")\n",
        "print(f\"Average time per query: {lance_batch_time/len(test_queries):.4f} seconds\")\n",
        "\n",
        "# Performance comparison\n",
        "print(f\"\\nBatch performance comparison:\")\n",
        "print(f\"Simple cosine: {cosine_batch_time:.4f}s total ({cosine_batch_time/len(test_queries):.4f}s per query)\")\n",
        "print(f\"LanceDB:       {lance_batch_time:.4f}s total ({lance_batch_time/len(test_queries):.4f}s per query)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* While transformer embeddings dramatically improve search accuracy over TF-IDF (98% vs 85% HITS@1), for such a small dataset, the simple cosine search is faster than vector database operations.\n",
        "* Try scaling up the size for further comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCALABILITY SIMULATION\n",
            "----------------------------------------\n",
            "Creating scaled dataset for scalability test...\n",
            "Scaled dataset size: 2595 products\n",
            "Scaled embeddings shape: (2595, 384)\n",
            "\n",
            "Creating scaled LanceDB table...\n",
            "Created LanceDB table with 2595 vectors\n",
            "Vector dimension: 384\n",
            "Database path: ../src/vector_databases/lancedb_scaled\n",
            "\n",
            "Testing search performance on scaled data with query: 'coffee maker'\n",
            "\n",
            "Simple cosine similarity (scaled):\n",
            "Search time: 0.0429 seconds\n",
            "\n",
            "LanceDB (scaled):\n",
            "Search time: 0.0311 seconds\n",
            "\n",
            "----  Scalability Analysis  ----\n",
            "Original dataset (519 products):\n",
            "  Simple cosine: 0.1697s\n",
            "  LanceDB:       0.1741s\n",
            "\n",
            "Scaled dataset (2595 products):\n",
            "  Simple cosine: 0.0429s (slowdown: 0.25x)\n",
            "  LanceDB:       0.0311s (slowdown: 0.18x)\n",
            "\n",
            "LanceDB advantage on scaled data: 1.38x faster\n"
          ]
        }
      ],
      "source": [
        "print(\"SCALABILITY SIMULATION\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "def create_scaled_dataset(df, embeddings, scale_factor=5):\n",
        "    \"\"\"Create a larger dataset by replicating and slightly modifying data\"\"\"\n",
        "    scaled_df_list = []\n",
        "    scaled_embeddings_list = []\n",
        "    \n",
        "    for i in range(scale_factor):\n",
        "        # Create copy with modified product_ids to avoid duplicates\n",
        "        df_copy = df.copy()\n",
        "        df_copy['product_id'] = df_copy['product_id'] + f\"_copy_{i}\"\n",
        "        scaled_df_list.append(df_copy)\n",
        "        \n",
        "        # Add small noise to embeddings to simulate variation\n",
        "        noise = np.random.normal(0, 0.001, embeddings.shape)\n",
        "        scaled_embeddings_list.append(embeddings + noise)\n",
        "    \n",
        "    scaled_df = pd.concat(scaled_df_list, ignore_index=True)\n",
        "    scaled_embeddings = np.vstack(scaled_embeddings_list)\n",
        "    \n",
        "    return scaled_df, scaled_embeddings\n",
        "\n",
        "# Create scaled dataset (5x larger = ~2,500 products)\n",
        "print(\"Creating scaled dataset for scalability test...\")\n",
        "scaled_df, scaled_embeddings = create_scaled_dataset(df_baseline, transformer_embeddings, scale_factor=5)\n",
        "print(f\"Scaled dataset size: {scaled_df.shape[0]} products\")\n",
        "print(f\"Scaled embeddings shape: {scaled_embeddings.shape}\")\n",
        "\n",
        "# Create scaled LanceDB table\n",
        "print(\"\\nCreating scaled LanceDB table...\")\n",
        "scaled_db, scaled_lance_table = create_lancedb_table(\n",
        "    scaled_df, scaled_embeddings, \n",
        "    db_path=\"../src/vector_databases/lancedb_scaled\"\n",
        ")\n",
        "\n",
        "# Test performance on scaled data\n",
        "test_query_scaled = \"coffee maker\"\n",
        "print(f\"\\nTesting search performance on scaled data with query: '{test_query_scaled}'\")\n",
        "\n",
        "# Simple cosine on scaled data\n",
        "print(\"\\nSimple cosine similarity (scaled):\")\n",
        "start_time = time.time()\n",
        "scaled_cosine_results = simple_cosine_search(\n",
        "    test_query_scaled, scaled_df, scaled_embeddings, transformer_model, top_k=10\n",
        ")\n",
        "scaled_cosine_time = time.time() - start_time\n",
        "print(f\"Search time: {scaled_cosine_time:.4f} seconds\")\n",
        "\n",
        "# LanceDB on scaled data\n",
        "print(\"\\nLanceDB (scaled):\")\n",
        "start_time = time.time()\n",
        "scaled_lance_results = lancedb_search(\n",
        "    test_query_scaled, scaled_df, scaled_lance_table, transformer_model, top_k=10\n",
        ")\n",
        "scaled_lance_time = time.time() - start_time\n",
        "print(f\"Search time: {scaled_lance_time:.4f} seconds\")\n",
        "\n",
        "# Performance scaling analysis\n",
        "print(f\"\\n----  Scalability Analysis  ----\")\n",
        "print(f\"Original dataset ({len(df_baseline)} products):\")\n",
        "print(f\"  Simple cosine: {simple_search_time:.4f}s\")\n",
        "print(f\"  LanceDB:       {lance_search_time:.4f}s\")\n",
        "print(f\"\\nScaled dataset ({len(scaled_df)} products):\")\n",
        "print(f\"  Simple cosine: {scaled_cosine_time:.4f}s (slowdown: {scaled_cosine_time/simple_search_time:.2f}x)\")\n",
        "print(f\"  LanceDB:       {scaled_lance_time:.4f}s (slowdown: {scaled_lance_time/lance_search_time:.2f}x)\")\n",
        "\n",
        "if scaled_lance_time > 0:\n",
        "    scaled_speedup = scaled_cosine_time / scaled_lance_time\n",
        "    print(f\"\\nLanceDB advantage on scaled data: {scaled_speedup:.2f}x faster\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 11. Key Findings and Recommendations\n",
        "\n",
        "Let's summarize our findings about when and why vector databases provide value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KEY FINDINGS SUMMARY\n",
            "\n",
            " ACCURACY COMPARISON:\n",
            "     TF-IDF Baseline:        HITS@1: 0.849, MRR: 0.869\n",
            "     Simple Cosine (Trans):  HITS@1: 0.981, MRR: 0.981\n",
            "     LanceDB (Trans):        HITS@1: 0.981, MRR: 0.981\n",
            "\n",
            " PERFORMANCE CHARACTERISTICS:\n",
            "     Small dataset (519 products):\n",
            "       - Simple cosine: 0.1697s\n",
            "       - LanceDB:       0.1741s\n",
            "     Scaled dataset (2595 products):\n",
            "       - Simple cosine: 0.0429s\n",
            "       - LanceDB:       0.0311s\n"
          ]
        }
      ],
      "source": [
        "# Summarize findings\n",
        "print(\"KEY FINDINGS SUMMARY\")\n",
        "\n",
        "print(\"\\n ACCURACY COMPARISON:\")\n",
        "print(f\"     TF-IDF Baseline:        HITS@1: {tfidf_metrics['hits_at_1']:.3f}, MRR: {tfidf_metrics['mrr']:.3f}\")\n",
        "print(f\"     Simple Cosine (Trans):  HITS@1: {cosine_metrics['hits_at_1']:.3f}, MRR: {cosine_metrics['mrr']:.3f}\")\n",
        "print(f\"     LanceDB (Trans):        HITS@1: {lance_metrics['hits_at_1']:.3f}, MRR: {lance_metrics['mrr']:.3f}\")\n",
        "\n",
        "print(\"\\n PERFORMANCE CHARACTERISTICS:\")\n",
        "print(f\"     Small dataset ({len(df_baseline)} products):\")\n",
        "print(f\"       - Simple cosine: {simple_search_time:.4f}s\")\n",
        "print(f\"       - LanceDB:       {lance_search_time:.4f}s\")\n",
        "print(f\"     Scaled dataset ({len(scaled_df)} products):\")\n",
        "print(f\"       - Simple cosine: {scaled_cosine_time:.4f}s\")\n",
        "print(f\"       - LanceDB:       {scaled_lance_time:.4f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Vector databases allow metadata filtering and faster processing with scale\n",
        "* Some potential next steps:\n",
        "  * try out hybrid search (semantic + keyword)\n",
        "  * caching for popular queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save evaluation results\n",
        "vector_db_results = {\n",
        "    'method_comparison': {\n",
        "        'tfidf_baseline': tfidf_metrics,\n",
        "        'simple_cosine': cosine_metrics,\n",
        "        'lancedb': lance_metrics\n",
        "    },\n",
        "    'performance_analysis': {\n",
        "        'small_dataset_size': len(df_baseline),\n",
        "        'scaled_dataset_size': len(scaled_df),\n",
        "        'simple_cosine_time_small': simple_search_time,\n",
        "        'lancedb_time_small': lance_search_time,\n",
        "        'simple_cosine_time_scaled': scaled_cosine_time,\n",
        "        'lancedb_time_scaled': scaled_lance_time\n",
        "    },\n",
        "    'model_info': {\n",
        "        'transformer_model': model_name,\n",
        "        'embedding_dimension': transformer_embeddings.shape[1],\n",
        "        'evaluation_queries': len(df_baseline['query'].unique())\n",
        "    },\n",
        "    'conclusions': {\n",
        "        'best_method_hits1': comparison_df.loc[comparison_df['HITS@1'].idxmax(), 'Method'],\n",
        "        'best_method_mrr': comparison_df.loc[comparison_df['MRR'].idxmax(), 'Method'],\n",
        "        'recommendation': 'LanceDB recommended for production due to metadata filtering and scalability'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save results\n",
        "with open(f\"../src/results/vector_database/vector_database_evaluation.pkl\", \"wb\") as f:\n",
        "    pickle.dump(vector_db_results, f)\n",
        "\n",
        "# Save comparison table as CSV\n",
        "comparison_df.to_csv(f\"../src/results/vector_database/method_comparison.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
